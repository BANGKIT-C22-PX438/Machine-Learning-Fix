{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chicken",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKTp0VtRTnqSek5rKCn/mD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christoffelk/Machine-Learning-Fix/blob/main/chicken.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1EWpzbPETPqX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip = \"/tmp/Chicken.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "vlvP_BLwTZxA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = \"/tmp/typeoffases\"\n",
        "\n",
        "if os.path.exists(source_dir):\n",
        "  shutil.rmtree(source_dir)\n",
        "\n",
        "def create_train_test_dirs(source_path):\n",
        "  train_dir = os.path.join(source_path,\"training\")\n",
        "  testing_dir = os.path.join(source_path,\"testing\")\n",
        "\n",
        "  os.makedirs(train_dir)\n",
        "  os.makedirs(testing_dir)\n",
        "\n",
        "  train_salmo_dir = os.path.join(train_dir,\"salmo\")\n",
        "  train_healthy_dir = os.path.join(train_dir,\"healthy\")\n",
        "  train_cocci_dir = os.path.join(train_dir,\"cocci\")\n",
        "  train_ncd_dir = os.path.join(train_dir,\"ncd\")\n",
        "\n",
        "  os.makedirs(train_salmo_dir)\n",
        "  os.makedirs(train_healthy_dir)\n",
        "  os.makedirs(train_cocci_dir)\n",
        "  os.makedirs(train_ncd_dir)\n",
        "\n",
        "  test_salmo_dir = os.path.join(testing_dir,\"salmo\")\n",
        "  test_healthy_dir = os.path.join(testing_dir,\"healthy\")\n",
        "  test_cocci_dir =os.path.join(testing_dir,\"cocci\")\n",
        "  test_ncd_dir = os.path.join(testing_dir,\"ncd\")\n",
        "\n",
        "  os.makedirs(test_salmo_dir)\n",
        "  os.makedirs(test_healthy_dir)\n",
        "  os.makedirs(test_cocci_dir)\n",
        "  os.makedirs(test_ncd_dir)\n",
        "\n",
        "try:\n",
        "  create_train_test_dirs(source_path=source_dir)\n",
        "except FileExistsError:\n",
        "  print(\"File already exist\")\n"
      ],
      "metadata": {
        "id": "9nZf8XS0T5nI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE,TRAINING,TESTING,SPLIT_SIZE):\n",
        "  file_not_zero=[]\n",
        "  for files in os.listdir(SOURCE):\n",
        "    if os.path.getsize(SOURCE+files)>0:\n",
        "      file_not_zero.append(files)\n",
        "    else:\n",
        "      print(\"{} is zero length\".format(files))\n",
        "    \n",
        "    training_size = int(len(file_not_zero)* SPLIT_SIZE)\n",
        "    testing_size = int(len(file_not_zero) - training_size)\n",
        "    shuffle = random.sample(file_not_zero,len(file_not_zero))\n",
        "    training_file = shuffle[0:training_size]\n",
        "    testing_file = shuffle[-testing_size:]\n",
        "  \n",
        "  for files in training_file:\n",
        "    source = SOURCE + files\n",
        "    destination = TRAINING+files\n",
        "    copyfile(source,destination)\n",
        "\n",
        "  for files in testing_file:\n",
        "    source = SOURCE + files\n",
        "    destination = TESTING + files\n",
        "    copyfile(source,destination)"
      ],
      "metadata": {
        "id": "0SpFa-oVMZcy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SALMO_SOURCE_DIR = \"/tmp/chickenfasespart/salmo/\"\n",
        "HEALTHY_SOURCE_DIR = \"/tmp/chickenfasespart/healthy/\"\n",
        "COCCI_SOURCE_DIR = \"/tmp/chickenfasespart/cocci/\"\n",
        "NCD_SOURCE_DIR = \"/tmp/chickenfasespart/ncd/\"\n",
        "\n",
        "TRAINING_DIR = \"/tmp/typeoffases/training/\"\n",
        "TESTING_DIR = \"/tmp/typeoffases/testing/\"\n",
        "\n",
        "TRAINING_SALMO_DIR = os.path.join(TRAINING_DIR,\"salmo/\")\n",
        "TESTING_SALMO_DIR = os.path.join(TESTING_DIR,\"salmo/\")\n",
        "\n",
        "TRAINING_HEALTHY_DIR = os.path.join(TRAINING_DIR,\"healthy/\")\n",
        "TESTING_HEALTHY_DIR = os.path.join(TESTING_DIR,\"healthy/\")\n",
        "\n",
        "TRAINING_COCCI_DIR = os.path.join(TRAINING_DIR,\"cocci/\")\n",
        "TESTING_COCCI_DIR = os.path.join(TESTING_DIR,\"cocci/\")\n",
        "\n",
        "TRAINING_NCD_DIR = os.path.join(TRAINING_DIR,\"ncd/\")\n",
        "TESTING_NCD_DIR = os.path.join(TESTING_DIR,\"ncd/\")\n",
        "\n",
        "if len(os.listdir(TRAINING_SALMO_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_SALMO_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_HEALTHY_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_COCCI_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_COCCI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_NCD_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_NCD_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_SALMO_DIR))>0:\n",
        "  for file in os.scandir(TESTING_SALMO_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_HEALTHY_DIR))>0:\n",
        "  for file in os.scandir(TESTING_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_COCCI_DIR))>0:\n",
        "  for file in os.scandir(TESTING_COCCI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_NCD_DIR))>0:\n",
        "  for file in os.scandir(TESTING_NCD_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "\n",
        "split_size = .9\n",
        "split_data(SALMO_SOURCE_DIR,TRAINING_SALMO_DIR,TESTING_SALMO_DIR,split_size)\n",
        "split_data(HEALTHY_SOURCE_DIR,TRAINING_HEALTHY_DIR,TESTING_HEALTHY_DIR,split_size)\n",
        "split_data(COCCI_SOURCE_DIR,TRAINING_COCCI_DIR,TESTING_COCCI_DIR,split_size)\n",
        "split_data(NCD_SOURCE_DIR,TRAINING_NCD_DIR,TESTING_NCD_DIR,split_size)\n",
        "\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_SALMO_DIR))} images of salmo for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_HEALTHY_DIR))} images of healhy for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_COCCI_DIR))} images of cocci for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_NCD_DIR))} images of ncd for training\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(TESTING_SALMO_DIR))} images of salmo for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_HEALTHY_DIR))} images of healthy for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_COCCI_DIR))} images of cocci for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_NCD_DIR))} images of ncd for testing\")"
      ],
      "metadata": {
        "id": "RCJ0VdwqNbxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b25dfa1-a31b-42ab-9d5a-6984df1a3a4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 2362 images of salmo for training\n",
            "There are 2163 images of healhy for training\n",
            "There are 2228 images of cocci for training\n",
            "There are 505 images of ncd for training\n",
            "There are 263 images of salmo for testing\n",
            "There are 241 images of healthy for testing\n",
            "There are 248 images of cocci for testing\n",
            "There are 57 images of ncd for testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generators(TRAINING_DIR,VALIDATION_DIR):\n",
        "  train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size =100,\n",
        "                                                      class_mode=\"categorical\",\n",
        "                                                      target_size=(224,224))\n",
        "  \n",
        "  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                               batch_size=100,\n",
        "                                                               class_mode = \"categorical\",\n",
        "                                                               target_size=(224,224))\n",
        "  \n",
        "  return train_generator,validation_generator\n",
        "\n"
      ],
      "metadata": {
        "id": "Uu_kB3N1Skn2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator,validation_generator = train_val_generators(TRAINING_DIR,TESTING_DIR)"
      ],
      "metadata": {
        "id": "qSblhMO5T9Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acd387b-0020-406e-cce3-90dbe91fb15c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7258 images belonging to 4 classes.\n",
            "Found 809 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    tf.keras.layers.Dense(4, activation='softmax')  \n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "ODxxMKZJUG1c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "6YVxDqnaY4f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89b5eb0-c799-4511-907b-1caf58bba4db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "73/73 [==============================] - 336s 5s/step - loss: 1.0632 - accuracy: 0.6465 - val_loss: 0.6182 - val_accuracy: 0.7590\n",
            "Epoch 2/15\n",
            "73/73 [==============================] - 334s 5s/step - loss: 0.5556 - accuracy: 0.7973 - val_loss: 0.4988 - val_accuracy: 0.8269\n",
            "Epoch 3/15\n",
            "73/73 [==============================] - 329s 5s/step - loss: 0.4299 - accuracy: 0.8486 - val_loss: 0.4824 - val_accuracy: 0.8418\n",
            "Epoch 4/15\n",
            "73/73 [==============================] - 330s 5s/step - loss: 0.3180 - accuracy: 0.8878 - val_loss: 0.4061 - val_accuracy: 0.8616\n",
            "Epoch 5/15\n",
            "73/73 [==============================] - 332s 5s/step - loss: 0.2317 - accuracy: 0.9222 - val_loss: 0.3167 - val_accuracy: 0.9023\n",
            "Epoch 6/15\n",
            "73/73 [==============================] - 332s 5s/step - loss: 0.1600 - accuracy: 0.9470 - val_loss: 0.3052 - val_accuracy: 0.8986\n",
            "Epoch 7/15\n",
            "73/73 [==============================] - 331s 5s/step - loss: 0.1286 - accuracy: 0.9560 - val_loss: 0.3130 - val_accuracy: 0.8925\n",
            "Epoch 8/15\n",
            "73/73 [==============================] - 333s 5s/step - loss: 0.0936 - accuracy: 0.9691 - val_loss: 0.3020 - val_accuracy: 0.9073\n",
            "Epoch 9/15\n",
            "73/73 [==============================] - 334s 5s/step - loss: 0.0747 - accuracy: 0.9764 - val_loss: 0.3054 - val_accuracy: 0.9098\n",
            "Epoch 10/15\n",
            "73/73 [==============================] - 332s 5s/step - loss: 0.0567 - accuracy: 0.9831 - val_loss: 0.2728 - val_accuracy: 0.9320\n",
            "Epoch 11/15\n",
            "73/73 [==============================] - 330s 5s/step - loss: 0.0504 - accuracy: 0.9855 - val_loss: 0.3993 - val_accuracy: 0.8999\n",
            "Epoch 12/15\n",
            "73/73 [==============================] - 331s 5s/step - loss: 0.0392 - accuracy: 0.9880 - val_loss: 0.3319 - val_accuracy: 0.9209\n",
            "Epoch 13/15\n",
            "73/73 [==============================] - 355s 5s/step - loss: 0.0276 - accuracy: 0.9937 - val_loss: 0.3481 - val_accuracy: 0.9221\n",
            "Epoch 14/15\n",
            "73/73 [==============================] - 340s 5s/step - loss: 0.0260 - accuracy: 0.9941 - val_loss: 0.3380 - val_accuracy: 0.9122\n",
            "Epoch 15/15\n",
            "73/73 [==============================] - 351s 5s/step - loss: 0.0214 - accuracy: 0.9948 - val_loss: 0.3073 - val_accuracy: 0.9258\n"
          ]
        }
      ]
    }
  ]
}