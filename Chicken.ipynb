{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of chicken",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christoffelk/Machine-Learning-Fix/blob/main/Chicken.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EWpzbPETPqX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras \n",
        "from shutil import copyfile\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip = \"/tmp/Chicken.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "vlvP_BLwTZxA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = \"/tmp/typeoffases\"\n",
        "\n",
        "if os.path.exists(source_dir):\n",
        "  shutil.rmtree(source_dir)\n",
        "else:\n",
        "  os.makedirs(source_dir)\n",
        "\n",
        "def create_train_test_dirs(source_path):\n",
        "  train_dir = os.path.join(source_path,\"training\")\n",
        "  testing_dir = os.path.join(source_path,\"testing\")\n",
        "\n",
        "  os.makedirs(train_dir)\n",
        "  os.makedirs(testing_dir)\n",
        "\n",
        "  train_salmo_dir = os.path.join(train_dir,\"salmo\")\n",
        "  train_healthy_dir = os.path.join(train_dir,\"healthy\")\n",
        "  train_cocci_dir = os.path.join(train_dir,\"cocci\")\n",
        "  train_ncd_dir = os.path.join(train_dir,\"ncd\")\n",
        "\n",
        "  os.makedirs(train_salmo_dir)\n",
        "  os.makedirs(train_healthy_dir)\n",
        "  os.makedirs(train_cocci_dir)\n",
        "  os.makedirs(train_ncd_dir)\n",
        "\n",
        "  test_salmo_dir = os.path.join(testing_dir,\"salmo\")\n",
        "  test_healthy_dir = os.path.join(testing_dir,\"healthy\")\n",
        "  test_cocci_dir =os.path.join(testing_dir,\"cocci\")\n",
        "  test_ncd_dir = os.path.join(testing_dir,\"ncd\")\n",
        "\n",
        "  os.makedirs(test_salmo_dir)\n",
        "  os.makedirs(test_healthy_dir)\n",
        "  os.makedirs(test_cocci_dir)\n",
        "  os.makedirs(test_ncd_dir)\n",
        "\n",
        "try:\n",
        "  create_train_test_dirs(source_path=source_dir)\n",
        "except FileExistsError:\n",
        "  print(\"File already exist\")\n"
      ],
      "metadata": {
        "id": "9nZf8XS0T5nI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE,TRAINING,TESTING,SPLIT_SIZE):\n",
        "  file_not_zero=[]\n",
        "  for files in os.listdir(SOURCE):\n",
        "    if os.path.getsize(SOURCE+files)>0:\n",
        "      file_not_zero.append(files)\n",
        "    else:\n",
        "      print(\"{} is zero length\".format(files))\n",
        "    \n",
        "    training_size = int(len(file_not_zero)* SPLIT_SIZE)\n",
        "    testing_size = int(len(file_not_zero) - training_size)\n",
        "    shuffle = random.sample(file_not_zero,len(file_not_zero))\n",
        "    training_file = shuffle[0:training_size]\n",
        "    testing_file = shuffle[-testing_size:]\n",
        "  \n",
        "  for files in training_file:\n",
        "    source = SOURCE + files\n",
        "    destination = TRAINING+files\n",
        "    copyfile(source,destination)\n",
        "\n",
        "  for files in testing_file:\n",
        "    source = SOURCE + files\n",
        "    destination = TESTING + files\n",
        "    copyfile(source,destination)"
      ],
      "metadata": {
        "id": "0SpFa-oVMZcy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SALMO_SOURCE_DIR = \"/tmp/chickenfasespart/salmo/\"\n",
        "HEALTHY_SOURCE_DIR = \"/tmp/chickenfasespart/healthy/\"\n",
        "COCCI_SOURCE_DIR = \"/tmp/chickenfasespart/cocci/\"\n",
        "NCD_SOURCE_DIR = \"/tmp/chickenfasespart/ncd/\"\n",
        "\n",
        "TRAINING_DIR = \"/tmp/typeoffases/training/\"\n",
        "TESTING_DIR = \"/tmp/typeoffases/testing/\"\n",
        "\n",
        "TRAINING_SALMO_DIR = os.path.join(TRAINING_DIR,\"salmo/\")\n",
        "TESTING_SALMO_DIR = os.path.join(TESTING_DIR,\"salmo/\")\n",
        "\n",
        "TRAINING_HEALTHY_DIR = os.path.join(TRAINING_DIR,\"healthy/\")\n",
        "TESTING_HEALTHY_DIR = os.path.join(TESTING_DIR,\"healthy/\")\n",
        "\n",
        "TRAINING_COCCI_DIR = os.path.join(TRAINING_DIR,\"cocci/\")\n",
        "TESTING_COCCI_DIR = os.path.join(TESTING_DIR,\"cocci/\")\n",
        "\n",
        "TRAINING_NCD_DIR = os.path.join(TRAINING_DIR,\"ncd/\")\n",
        "TESTING_NCD_DIR = os.path.join(TESTING_DIR,\"ncd/\")\n",
        "\n",
        "if len(os.listdir(TRAINING_SALMO_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_SALMO_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_HEALTHY_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_COCCI_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_COCCI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_NCD_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_NCD_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_SALMO_DIR))>0:\n",
        "  for file in os.scandir(TESTING_SALMO_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_HEALTHY_DIR))>0:\n",
        "  for file in os.scandir(TESTING_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_COCCI_DIR))>0:\n",
        "  for file in os.scandir(TESTING_COCCI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_NCD_DIR))>0:\n",
        "  for file in os.scandir(TESTING_NCD_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "\n",
        "split_size = .9\n",
        "split_data(SALMO_SOURCE_DIR,TRAINING_SALMO_DIR,TESTING_SALMO_DIR,split_size)\n",
        "split_data(HEALTHY_SOURCE_DIR,TRAINING_HEALTHY_DIR,TESTING_HEALTHY_DIR,split_size)\n",
        "split_data(COCCI_SOURCE_DIR,TRAINING_COCCI_DIR,TESTING_COCCI_DIR,split_size)\n",
        "split_data(NCD_SOURCE_DIR,TRAINING_NCD_DIR,TESTING_NCD_DIR,split_size)\n",
        "\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_SALMO_DIR))} images of salmo for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_HEALTHY_DIR))} images of healhy for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_COCCI_DIR))} images of cocci for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_NCD_DIR))} images of ncd for training\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(TESTING_SALMO_DIR))} images of salmo for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_HEALTHY_DIR))} images of healthy for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_COCCI_DIR))} images of cocci for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_NCD_DIR))} images of ncd for testing\")"
      ],
      "metadata": {
        "id": "RCJ0VdwqNbxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598abd8e-ffc6-4f9d-b27f-1b30471b135b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 2362 images of salmo for training\n",
            "There are 2163 images of healhy for training\n",
            "There are 2228 images of cocci for training\n",
            "There are 505 images of ncd for training\n",
            "There are 263 images of salmo for testing\n",
            "There are 241 images of healthy for testing\n",
            "There are 248 images of cocci for testing\n",
            "There are 57 images of ncd for testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generators(TRAINING_DIR,VALIDATION_DIR):\n",
        "  train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size =100,\n",
        "                                                      class_mode=\"categorical\",\n",
        "                                                      target_size=(224,224))\n",
        "  \n",
        "  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                               batch_size=100,\n",
        "                                                               class_mode = \"categorical\",\n",
        "                                                               target_size=(224,224))\n",
        "  \n",
        "  return train_generator,validation_generator\n",
        "\n"
      ],
      "metadata": {
        "id": "Uu_kB3N1Skn2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator,validation_generator = train_val_generators(TRAINING_DIR,TESTING_DIR)"
      ],
      "metadata": {
        "id": "qSblhMO5T9Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac51eea-375a-4f17-b6c2-56108acfcc55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7258 images belonging to 4 classes.\n",
            "Found 809 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    if(logs.get('accuracy') >= 0.90 and logs.get('val_accuracy') >=0.90):\n",
        "      print(\"stop the training because the accuracy is already on target\")\n",
        "      self.model.stop_training=True"
      ],
      "metadata": {
        "id": "BhDYO3151FRD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    tf.keras.layers.Dense(4, activation='softmax')  \n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "ODxxMKZJUG1c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "callbacks = Callback()\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    callbacks=[callbacks],\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "6YVxDqnaY4f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b318ac7a-5321-46d8-d32c-2c2f2f7b3e56"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "73/73 [==============================] - 343s 5s/step - loss: 1.1824 - accuracy: 0.6615 - val_loss: 0.6307 - val_accuracy: 0.7701\n",
            "Epoch 2/15\n",
            "73/73 [==============================] - 333s 5s/step - loss: 0.4965 - accuracy: 0.8220 - val_loss: 0.4662 - val_accuracy: 0.8443\n",
            "Epoch 3/15\n",
            "73/73 [==============================] - 336s 5s/step - loss: 0.3762 - accuracy: 0.8658 - val_loss: 0.5726 - val_accuracy: 0.8010\n",
            "Epoch 4/15\n",
            "73/73 [==============================] - 334s 5s/step - loss: 0.2834 - accuracy: 0.9036 - val_loss: 0.3589 - val_accuracy: 0.8727\n",
            "Epoch 5/15\n",
            "73/73 [==============================] - 344s 5s/step - loss: 0.1934 - accuracy: 0.9339 - val_loss: 0.3833 - val_accuracy: 0.8764\n",
            "Epoch 6/15\n",
            "73/73 [==============================] - 334s 5s/step - loss: 0.1570 - accuracy: 0.9457 - val_loss: 0.4177 - val_accuracy: 0.8789\n",
            "Epoch 7/15\n",
            "73/73 [==============================] - 339s 5s/step - loss: 0.1133 - accuracy: 0.9620 - val_loss: 0.4078 - val_accuracy: 0.8850\n",
            "Epoch 8/15\n",
            "73/73 [==============================] - 337s 5s/step - loss: 0.1059 - accuracy: 0.9645 - val_loss: 0.4239 - val_accuracy: 0.8826\n",
            "Epoch 9/15\n",
            "73/73 [==============================] - 337s 5s/step - loss: 0.1027 - accuracy: 0.9660 - val_loss: 0.4061 - val_accuracy: 0.8789\n",
            "Epoch 10/15\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9780stop the training because the accuracy is already on target\n",
            "73/73 [==============================] - 332s 5s/step - loss: 0.0682 - accuracy: 0.9780 - val_loss: 0.3672 - val_accuracy: 0.9036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_dir = 'tmp/modelexport'\n",
        "tf.saved_model.save(model,export_dir)"
      ],
      "metadata": {
        "id": "UvzTMogDNaYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2a2cd5-ee16-44b1-eeff-294c4af0c917"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tmp/modelexport/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = \"Speed\"\n",
        "if mode == 'Storage' :\n",
        "  optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
        "elif mode == 'Speed':\n",
        "  optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "else:\n",
        "  optimization = tf.lite.Optimize.DEFAULT"
      ],
      "metadata": {
        "id": "Y2LbXfvjNr4_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "converter.optimizations = [optimization]\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "NkW-6tXpOFP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff14091-5537-4cb0-f3b8-b1f97d5f0a28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_file = pathlib.Path('/model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "id": "aGyt9nAmOTl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504d6063-3495-44be-a9a9-04f1c3c9179c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22186512"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}