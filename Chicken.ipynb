{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christoffelk/Machine-Learning-Fix/blob/main/Chicken.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EWpzbPETPqX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras \n",
        "from shutil import copyfile\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlvP_BLwTZxA"
      },
      "outputs": [],
      "source": [
        "local_zip = \"/tmp/Chicken.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nZf8XS0T5nI"
      },
      "outputs": [],
      "source": [
        "source_dir = \"/tmp/typeoffases\"\n",
        "\n",
        "if os.path.exists(source_dir):\n",
        "  shutil.rmtree(source_dir)\n",
        "else:\n",
        "  os.makedirs(source_dir)\n",
        "\n",
        "def create_train_test_dirs(source_path):\n",
        "  train_dir = os.path.join(source_path,\"training\")\n",
        "  testing_dir = os.path.join(source_path,\"testing\")\n",
        "\n",
        "  os.makedirs(train_dir)\n",
        "  os.makedirs(testing_dir)\n",
        "\n",
        "  train_salmo_dir = os.path.join(train_dir,\"salmo\")\n",
        "  train_healthy_dir = os.path.join(train_dir,\"healthy\")\n",
        "  train_cocci_dir = os.path.join(train_dir,\"cocci\")\n",
        "  train_ncd_dir = os.path.join(train_dir,\"ncd\")\n",
        "\n",
        "  os.makedirs(train_salmo_dir)\n",
        "  os.makedirs(train_healthy_dir)\n",
        "  os.makedirs(train_cocci_dir)\n",
        "  os.makedirs(train_ncd_dir)\n",
        "\n",
        "  test_salmo_dir = os.path.join(testing_dir,\"salmo\")\n",
        "  test_healthy_dir = os.path.join(testing_dir,\"healthy\")\n",
        "  test_cocci_dir =os.path.join(testing_dir,\"cocci\")\n",
        "  test_ncd_dir = os.path.join(testing_dir,\"ncd\")\n",
        "\n",
        "  os.makedirs(test_salmo_dir)\n",
        "  os.makedirs(test_healthy_dir)\n",
        "  os.makedirs(test_cocci_dir)\n",
        "  os.makedirs(test_ncd_dir)\n",
        "\n",
        "try:\n",
        "  create_train_test_dirs(source_path=source_dir)\n",
        "except FileExistsError:\n",
        "  print(\"File already exist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SpFa-oVMZcy"
      },
      "outputs": [],
      "source": [
        "def split_data(SOURCE,TRAINING,TESTING,SPLIT_SIZE):\n",
        "  file_not_zero=[]\n",
        "  for files in os.listdir(SOURCE):\n",
        "    if os.path.getsize(SOURCE+files)>0:\n",
        "      file_not_zero.append(files)\n",
        "    else:\n",
        "      print(\"{} is zero length\".format(files))\n",
        "    \n",
        "    training_size = int(len(file_not_zero)* SPLIT_SIZE)\n",
        "    testing_size = int(len(file_not_zero) - training_size)\n",
        "    shuffle = random.sample(file_not_zero,len(file_not_zero))\n",
        "    training_file = shuffle[0:training_size]\n",
        "    testing_file = shuffle[-testing_size:]\n",
        "  \n",
        "  for files in training_file:\n",
        "    source = SOURCE + files\n",
        "    destination = TRAINING+files\n",
        "    copyfile(source,destination)\n",
        "\n",
        "  for files in testing_file:\n",
        "    source = SOURCE + files\n",
        "    destination = TESTING + files\n",
        "    copyfile(source,destination)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCJ0VdwqNbxW",
        "outputId": "63723d9e-7e06-4bfa-8a3d-5a56f6a10b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "There are 2362 images of salmo for training\n",
            "There are 2163 images of healhy for training\n",
            "There are 2228 images of cocci for training\n",
            "There are 505 images of ncd for training\n",
            "There are 263 images of salmo for testing\n",
            "There are 241 images of healthy for testing\n",
            "There are 248 images of cocci for testing\n",
            "There are 57 images of ncd for testing\n"
          ]
        }
      ],
      "source": [
        "SALMO_SOURCE_DIR = \"/tmp/chickenfasespart/salmo/\"\n",
        "HEALTHY_SOURCE_DIR = \"/tmp/chickenfasespart/healthy/\"\n",
        "COCCI_SOURCE_DIR = \"/tmp/chickenfasespart/cocci/\"\n",
        "NCD_SOURCE_DIR = \"/tmp/chickenfasespart/ncd/\"\n",
        "\n",
        "TRAINING_DIR = \"/tmp/typeoffases/training/\"\n",
        "TESTING_DIR = \"/tmp/typeoffases/testing/\"\n",
        "\n",
        "TRAINING_SALMO_DIR = os.path.join(TRAINING_DIR,\"salmo/\")\n",
        "TESTING_SALMO_DIR = os.path.join(TESTING_DIR,\"salmo/\")\n",
        "\n",
        "TRAINING_HEALTHY_DIR = os.path.join(TRAINING_DIR,\"healthy/\")\n",
        "TESTING_HEALTHY_DIR = os.path.join(TESTING_DIR,\"healthy/\")\n",
        "\n",
        "TRAINING_COCCI_DIR = os.path.join(TRAINING_DIR,\"cocci/\")\n",
        "TESTING_COCCI_DIR = os.path.join(TESTING_DIR,\"cocci/\")\n",
        "\n",
        "TRAINING_NCD_DIR = os.path.join(TRAINING_DIR,\"ncd/\")\n",
        "TESTING_NCD_DIR = os.path.join(TESTING_DIR,\"ncd/\")\n",
        "\n",
        "if len(os.listdir(TRAINING_SALMO_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_SALMO_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_HEALTHY_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_COCCI_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_COCCI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_NCD_DIR))>0:\n",
        "  for file in os.scandir(TRAINING_NCD_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_SALMO_DIR))>0:\n",
        "  for file in os.scandir(TESTING_SALMO_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_HEALTHY_DIR))>0:\n",
        "  for file in os.scandir(TESTING_HEALTHY_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_COCCI_DIR))>0:\n",
        "  for file in os.scandir(TESTING_COCCI_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TESTING_NCD_DIR))>0:\n",
        "  for file in os.scandir(TESTING_NCD_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "\n",
        "split_size = .9\n",
        "split_data(SALMO_SOURCE_DIR,TRAINING_SALMO_DIR,TESTING_SALMO_DIR,split_size)\n",
        "split_data(HEALTHY_SOURCE_DIR,TRAINING_HEALTHY_DIR,TESTING_HEALTHY_DIR,split_size)\n",
        "split_data(COCCI_SOURCE_DIR,TRAINING_COCCI_DIR,TESTING_COCCI_DIR,split_size)\n",
        "split_data(NCD_SOURCE_DIR,TRAINING_NCD_DIR,TESTING_NCD_DIR,split_size)\n",
        "\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_SALMO_DIR))} images of salmo for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_HEALTHY_DIR))} images of healhy for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_COCCI_DIR))} images of cocci for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_NCD_DIR))} images of ncd for training\")\n",
        "\n",
        "print(f\"There are {len(os.listdir(TESTING_SALMO_DIR))} images of salmo for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_HEALTHY_DIR))} images of healthy for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_COCCI_DIR))} images of cocci for testing\")\n",
        "print(f\"There are {len(os.listdir(TESTING_NCD_DIR))} images of ncd for testing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu_kB3N1Skn2"
      },
      "outputs": [],
      "source": [
        "def train_val_generators(TRAINING_DIR,VALIDATION_DIR):\n",
        "  train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip = True,\n",
        "                                     fill_mode = \"nearest\")\n",
        "  \n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size =126,\n",
        "                                                      class_mode=\"categorical\",\n",
        "                                                      target_size=(224,224))\n",
        "  \n",
        "  validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                               batch_size=126,\n",
        "                                                               class_mode = \"categorical\",\n",
        "                                                               target_size=(224,224))\n",
        "  \n",
        "  return train_generator,validation_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSblhMO5T9Ak",
        "outputId": "a85594b3-bb05-4b0e-88f9-8f2b2d785be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7258 images belonging to 4 classes.\n",
            "Found 809 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator,validation_generator = train_val_generators(TRAINING_DIR,TESTING_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BhDYO3151FRD"
      },
      "outputs": [],
      "source": [
        "class Callback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs={}):\n",
        "    if(logs.get('loss') <= 0.15 and logs.get('val_loss') <=0.1):\n",
        "      print(\"stop the training because the accuracy is already on target\")\n",
        "      self.model.stop_training=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ODxxMKZJUG1c"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu',input_shape=(224,224,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),  \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),    tf.keras.layers.MaxPooling2D(2,2),    \n",
        "tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
        "tf.keras.layers.MaxPooling2D(2,2)\n",
        ",tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    tf.keras.layers.Dense(4, activation='softmax')  \n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YVxDqnaY4f9",
        "outputId": "e7227cf4-77e3-4486-964d-986c65636dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "58/58 [==============================] - 926s 16s/step - loss: 0.9866 - accuracy: 0.5923 - val_loss: 0.7038 - val_accuracy: 0.7627\n",
            "Epoch 2/15\n",
            "58/58 [==============================] - 909s 16s/step - loss: 0.6414 - accuracy: 0.7727 - val_loss: 0.6657 - val_accuracy: 0.7651\n",
            "Epoch 3/15\n",
            "58/58 [==============================] - 906s 16s/step - loss: 0.6149 - accuracy: 0.7758 - val_loss: 0.7045 - val_accuracy: 0.7454\n",
            "Epoch 4/15\n",
            "58/58 [==============================] - 904s 16s/step - loss: 0.5637 - accuracy: 0.7929 - val_loss: 0.4895 - val_accuracy: 0.8356\n",
            "Epoch 5/15\n",
            "58/58 [==============================] - 902s 16s/step - loss: 0.4923 - accuracy: 0.8202 - val_loss: 0.4064 - val_accuracy: 0.8727\n",
            "Epoch 6/15\n",
            "58/58 [==============================] - 904s 16s/step - loss: 0.4377 - accuracy: 0.8446 - val_loss: 0.3771 - val_accuracy: 0.8603\n",
            "Epoch 7/15\n",
            "58/58 [==============================] - 902s 16s/step - loss: 0.3692 - accuracy: 0.8672 - val_loss: 0.2746 - val_accuracy: 0.9085\n",
            "Epoch 8/15\n",
            "58/58 [==============================] - 902s 16s/step - loss: 0.3596 - accuracy: 0.8730 - val_loss: 0.3176 - val_accuracy: 0.8739\n",
            "Epoch 9/15\n",
            "58/58 [==============================] - 901s 16s/step - loss: 0.3391 - accuracy: 0.8804 - val_loss: 0.2612 - val_accuracy: 0.9110\n",
            "Epoch 10/15\n",
            "58/58 [==============================] - 898s 15s/step - loss: 0.3154 - accuracy: 0.8883 - val_loss: 0.2361 - val_accuracy: 0.9258\n",
            "Epoch 11/15\n",
            "48/58 [=======================>......] - ETA: 2:31 - loss: 0.2952 - accuracy: 0.8938"
          ]
        }
      ],
      "source": [
        "model = create_model()\n",
        "callbacks = Callback()\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    callbacks=[callbacks],\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvzTMogDNaYe",
        "outputId": "9be72ae2-3b4e-4497-f333-e4287be1d0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: tmp/modelexport/assets\n"
          ]
        }
      ],
      "source": [
        "export_dir = 'tmp/modelexport'\n",
        "tf.saved_model.save(model,export_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2LbXfvjNr4_"
      },
      "outputs": [],
      "source": [
        "mode = \"Speed\"\n",
        "if mode == 'Storage' :\n",
        "  optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
        "elif mode == 'Speed':\n",
        "  optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "else:\n",
        "  optimization = tf.lite.Optimize.DEFAULT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkW-6tXpOFP_",
        "outputId": "fff50d82-341a-4267-c0c8-b37fb56c9df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_LATENCY is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "converter.optimizations = [optimization]\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGyt9nAmOTl0",
        "outputId": "7316f0a6-b69d-497b-8d7a-3c502cbc18e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19284688"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "tflite_model_file = pathlib.Path('/model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of chicken",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}